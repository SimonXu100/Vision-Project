{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMS 4731 Computer Vision -- Homework 3\n",
    "==========\n",
    "\n",
    "- In this homework, you will construct a panorama by stitching several individual and overlapping images together.\n",
    "    - **Problem 1: Homography (20 points)**\n",
    "        - Implement the `compute_homography` function.\n",
    "        - Implement the `apply_homography` function.\n",
    "    - **Problem 2: Warping (20 points)**\n",
    "        - Implement the `backward_warp_img` function.\n",
    "    - **Problem 3: SIFT and RANSAC (20 points)**\n",
    "        - Implement the `RANSAC` function.\n",
    "    - **Problem 4: Image Blending (20 points)**\n",
    "        - Implement the `blend_image_pair` function.\n",
    "    - **Problem 5: Creating Panoramas (20 points)**\n",
    "        - Implement the `stitch_img` function.\n",
    "        - Create a panorama using your own photos. \n",
    "\n",
    "- Your job is to implement the sections marked with TODO to complete the tasks.\n",
    "\n",
    "- Submission \n",
    "    - Please submit the notebook (ipynb and pdf) including the output of all cells.\n",
    "\n",
    "- Note: Please install OpenCV (version 3.4.2.16) by running the following command in the terminal\n",
    "    - `pip install opencv-python==3.4.2.16; pip install opencv-contrib-python==3.4.2.16`\n",
    "    - Otherwise, you may encounter error when running SIFT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup\n",
    "-----\n",
    "\n",
    "Before we get started, let's visualize the three separate images we ultimately want to stitch together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from IPython import display\n",
    "import sys\n",
    "import random\n",
    "import cv2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [15, 15]\n",
    "\n",
    "def load_image(filename):\n",
    "    img = np.asarray(Image.open(filename))\n",
    "    img = img.astype(\"float32\")/255.\n",
    "    return img\n",
    "\n",
    "def show_image(img):\n",
    "    plt.imshow(img, interpolation='nearest')\n",
    "    \n",
    "center_img = load_image(\"mountain_center.png\")\n",
    "left_img   = load_image(\"mountain_left.png\")\n",
    "right_img  = load_image(\"mountain_right.png\")\n",
    "\n",
    "show_image(np.concatenate([left_img, center_img, right_img], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 1: Homography\n",
    "=========\n",
    "\n",
    "You should finish implementing two functions below:\n",
    "\n",
    "1. **compute_homography(src, dst)** receives two matrices of points, which are each Nx2. The function should return the homography matrix H that maps points from the source to the target. This return value should be a 3x3 matrix. We have given you most of the solution already. You just need to implement the A matrix.\n",
    "\n",
    "2. **apply_homography(src, H)** receives points src (Nx2 matrix) and the homography transformation H (3x3 matrix). This function should use the homography matrix to transform src into the destination. Remember that you need to implement this using homogenous coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_homography(src, dst):\n",
    "    '''Computes the homography from src to dst.\n",
    "    \n",
    "    Input:\n",
    "        src: source points, shape (n, 2)\n",
    "        dst: destination points, shape (n, 2)\n",
    "    Output:\n",
    "        H: homography from source points to destination points, shape (3, 3)\n",
    "        \n",
    "    TODO: Implement the A matrix. \n",
    "    '''\n",
    "    \n",
    "    A = np.zeros([2*src.shape[0], 9])\n",
    "    # Your code here.\n",
    "    \n",
    "    w, v = np.linalg.eig(np.dot(A.T, A))\n",
    "    index = np.argmin(w)\n",
    "    H = v[:, index].reshape([3,3])\n",
    "    return H\n",
    "\n",
    "def apply_homography(src, H):\n",
    "    '''Applies a homography H onto the source points.\n",
    "    \n",
    "    Input:\n",
    "        src: source points, shape (n, 2)\n",
    "        H: homography from source points to destination points, shape (3, 3)\n",
    "    Output:\n",
    "        dst: destination points, shape (n, 2)\n",
    "    \n",
    "    TODO: Implement the apply_homography function\n",
    "    '''\n",
    "    pass "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To help you debug the homography code, we have provided a test below. This uses pairs of points (src_pts and dst_pts) to compute the homography. Then, it applies the homography on held-out points (test_pts), and visualizes the correspondence as red lines between the two images. If you have correctly implemented compute_homography() and apply_homography, the red lines should connect the same points in both images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_homography():\n",
    "    src_img = load_image('portrait.png')[:, :, :3]\n",
    "    dst_img = load_image('portrait_transformed.png')\n",
    "    whole_img = np.concatenate((src_img, dst_img), axis=1)\n",
    "\n",
    "    src_pts = np.matrix('347, 313; 502, 341; 386, 571; 621, 508')\n",
    "    dst_pts = np.matrix('274, 286; 436, 305; 305, 527; 615, 506')\n",
    "    H = compute_homography(src_pts, dst_pts)\n",
    "\n",
    "    test_pts = np.matrix('259, 505; 350, 371; 400, 675; 636, 104')\n",
    "    match_pts = apply_homography(test_pts, H)\n",
    "\n",
    "    match_pts_correct = np.matrix('195.13761083, 448.12645033;'\n",
    "                                  '275.27269386, 336.54819916;'\n",
    "                                  '317.37663747, 636.78403426;'\n",
    "                                  '618.50438823, 28.78963905')\n",
    "\n",
    "    print('Your solution differs from our solution by: %f'\n",
    "          % np.square(match_pts - match_pts_correct).sum())\n",
    "\n",
    "    for i in range(test_pts.shape[0]):\n",
    "        test_x = test_pts[i, 0]\n",
    "        test_y = test_pts[i, 1]\n",
    "        match_x = int(round(match_pts[i, 0] + 800))\n",
    "        match_y = int(round(match_pts[i, 1]))\n",
    "\n",
    "        cv2.line(whole_img,\n",
    "            (test_x, test_y), \n",
    "            (match_x, match_y), \n",
    "            (255, 0, 0), thickness=5)\n",
    "        cv2.circle(whole_img,\n",
    "            (test_x, test_y),\n",
    "            4, (255, 0, 0), thickness=10)\n",
    "        cv2.circle(whole_img,\n",
    "            (match_x, match_y),\n",
    "            4, (255, 0, 0), thickness=10)\n",
    "\n",
    "    print('If your solution is correct, the red lines will match to the same points in both images below:')\n",
    "    show_image(np.clip(whole_img, 0, 1)) \n",
    "\n",
    "test_homography()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 2: Warping\n",
    "=====\n",
    "\n",
    "When we map a source image to its destination image using a homography, we may encounter a problem where multiple pixels of the source image are mapped to the same point of its destination image. What's more, some pixels of the destination image may not be mapped to any pixels of source image. What should we do?\n",
    "\n",
    "Suppose we had homography $H$, source pixel $s$ with coordinates $(x_s, y_s)$, and destination pixel $d$ with coordinates $(x_d, y_d)$. Then, $H \\cdot \\tilde{s} = \\tilde{d}$ (where, $s$, $d$ are in homogenous space).\n",
    "\n",
    "To deal with this problem, we warp in the opposite direction: we map the pixels of the destination image back to source image, and then use the color in the source image as its color. More precisely, for each destination pixel $d = (x_d, y_d)$, we take $H^{-1} \\cdot \\tilde{d}$ to obtain the coordinate of its associated source pixel, $\\tilde{s}$ (from which $s$ can be found). If $s$ is within the bounds of the source image, we take the intensity of $s$ to be the intensity of $d$.\n",
    "\n",
    "Repeating this process over the entire destination image ensures that there are no gaps in the final result. This process is called \"backward warping\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_warp_img(src_img, H, dst_img_size):\n",
    "    '''Backward warping of the source image using a homography.\n",
    "    \n",
    "    Input:\n",
    "        src_img: source image, shape (m, n, 3)\n",
    "        H: homography from destination to source image, shape (3, 3)\n",
    "        dst_img_size: height and width of destination image, shape (2,)\n",
    "    Output:\n",
    "        dst_img: destination image, shape (m, n, 3)\n",
    "    \n",
    "    TODO: Implement the backward_warp_img function. \n",
    "    '''\n",
    "    pass\n",
    "\n",
    "def binary_mask(img):\n",
    "    '''Create a binary mask of the image content.\n",
    "    \n",
    "    Input:\n",
    "        img: source image, shape (m, n, 3)\n",
    "    Output:\n",
    "        mask: image of shape (m, n) and type 'int'. For pixel [i, j] of mask, if img[i, j] > 0 \n",
    "              in any of its channels, mask[i, j] = 1. Else, (if img[i, j] = 0), mask[i, j] = 0.\n",
    "    '''\n",
    "\n",
    "    mask = (img[:, :, 0] > 0) | (img[:, :, 1] > 0) | (img[:, :, 2] > 0)\n",
    "    mask = mask.astype(\"int\")\n",
    "    \n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the function below to help debug your implementation. If it is correct, it should warp Van Gogh's self-portrait onto the building side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_warp():\n",
    "    src_img = load_image('portrait_small.png')\n",
    "    canvas = load_image('Osaka.png')\n",
    "\n",
    "    src_pts = np.matrix('1, 1; 1, 400; 326, 1; 326, 400')\n",
    "    canvas_pts = np.matrix('100, 18; 84, 437; 276, 71; 286, 424')\n",
    "    H = compute_homography(src_pts, canvas_pts)\n",
    "\n",
    "    dst_img = backward_warp_img(src_img, np.linalg.inv(H), [canvas.shape[0], canvas.shape[1]])\n",
    "    dst_mask = 1 - binary_mask(dst_img)\n",
    "    dst_mask = np.stack((dst_mask,) * 3, -1)\n",
    "    out_img = np.multiply(canvas, dst_mask) + dst_img\n",
    "\n",
    "    warp_img = np.concatenate((canvas, out_img), axis=1)\n",
    "\n",
    "    show_image(np.clip(warp_img, 0, 1))\n",
    "    \n",
    "test_warp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 3: SIFT and RANSAC\n",
    "====\n",
    "\n",
    "SIFT Keypoints\n",
    "--------------\n",
    "\n",
    "So far, we have manually defined corresponding keypoints for both estimating homographies and warping. We want to automate this now. However, if we just take two photos, how do we know which points correspond? We could estimate SIFT keypoints, and take the nearest neighbor between them. The code below computes SIFT keypoints, and visualizes the matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genSIFTMatchPairs(img1, img2):\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    kp1, des1 = sift.detectAndCompute(img1, None)\n",
    "    kp2, des2 = sift.detectAndCompute(img2, None)\n",
    "\n",
    "    bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=False)\n",
    "    matches = bf.match(des1, des2)\n",
    "    matches = sorted(matches, key = lambda x:x.distance)\n",
    "    \n",
    "    pts1 = np.zeros((250,2))\n",
    "    pts2 = np.zeros((250,2))\n",
    "    for i in range(250):\n",
    "        pts1[i,:] = kp1[matches[i].queryIdx].pt\n",
    "        pts2[i,:] = kp2[matches[i].trainIdx].pt\n",
    "    \n",
    "    return pts1, pts2, matches[:250], kp1, kp2\n",
    "\n",
    "def test_matches():\n",
    "    img1 = cv2.imread('mountain_left.png')\n",
    "    img2 = cv2.imread('mountain_center.png')\n",
    "\n",
    "    pts1, pts2, matches, kp1, kp2 = genSIFTMatchPairs(img1, img2)\n",
    "\n",
    "    matching_result = cv2.drawMatches(img1, kp1, img2, kp2, matches, None, flags=2, matchColor=(0,0,255))\n",
    "    plt.imshow(cv2.cvtColor(matching_result, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "test_matches()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the matches are not all correct. There is a substantial amount of noise or incorrect matches. If we include these wrong matches in our homography estimation, what will happen? Think about this, and convince yourself why it will not work well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RANSAC\n",
    "------\n",
    "Instead, we will use RANSAC, which is an optimization algorithm that finds correspondences while also discarding the outliers. Implement the RANSAC function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RANSAC(Xs, Xd, max_iter, eps):\n",
    "    '''Finds correspondences between two sets of points using the RANSAC algorithm.\n",
    "    \n",
    "    Input:\n",
    "        Xs: the first set of points (source), shape [n, 2]\n",
    "        Xd: the second set of points (destination) matched to the first set, shape [n, 2]\n",
    "        max_iter: max iteration number of RANSAC\n",
    "        eps: tolerance of RANSAC\n",
    "    Output:\n",
    "        inliers_id: the indices of matched pairs when using the homography given by RANSAC\n",
    "        H: the homography, shape [3, 3]\n",
    "    \n",
    "    TODO: Implement the RANSAC function. \n",
    "    '''\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's visualize the matches between keypoints after using your RANSAC implementation. If you implemented RANSAC correctly, the outlier matches should be automatically discarded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_ransac():\n",
    "    img1 = cv2.imread('mountain_left.png')\n",
    "    img2 = cv2.imread('mountain_center.png')\n",
    "\n",
    "    pts1, pts2, matches, kp1, kp2 = genSIFTMatchPairs(img1, img2)\n",
    "    \n",
    "    inliers_idx, H = RANSAC(pts1, pts2, 500, 20)\n",
    "\n",
    "    new_matches = []\n",
    "    for i in range(len(inliers_idx)):\n",
    "        new_matches.append(matches[inliers_idx[i]])\n",
    "\n",
    "    matching_result = cv2.drawMatches(img1, kp1, img2, kp2, new_matches, None, flags=2, matchColor=(0,0,255))\n",
    "    plt.imshow(cv2.cvtColor(matching_result, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "test_ransac()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 4: Image Blending\n",
    "====\n",
    "\n",
    "We have now implemented code to estimate correspondences between photos, estimate the homography, and warp one image into the other image. Before we can build our panorama making application, the next piece we need is code to seamlessly blend two images together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage.morphology import distance_transform_edt as euc_dist\n",
    "\n",
    "def blend_image_pair(src_img, src_mask, dst_img, dst_mask, mode):\n",
    "    '''Given two images and their binary masks, blend the two images.\n",
    "    \n",
    "    Input:\n",
    "        src_img: First image to be blended, shape (m, n, 3)\n",
    "        src_mask: src_img's binary mask, shape (m, n)\n",
    "        dst_img: Second image to be blended, shape (m, n, 3)\n",
    "        dst_mask: dst_img's binary mask, shape (m, n)\n",
    "        mode: Blending mode, either \"overlay\" or \"blend\"\n",
    "    Output:\n",
    "        Blended image of shape (m, n, 3)\n",
    "    \n",
    "    TODO: Implement the blend_image_pair function.\n",
    "    '''\n",
    "    pass "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test your implementation, you can use the function below. It supports two modes. Setting mode=\"blend\" should seamlessly blend the two images. Setting mode=\"overlay\" will just combine them without any blending."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_blend(mode):\n",
    "    fish_img = load_image(\"escher_fish.png\")[:, :, :3]\n",
    "    horse_img = load_image(\"escher_horsemen.png\")[:, :, :3]\n",
    "\n",
    "    blend_img = blend_image_pair(fish_img, binary_mask(fish_img), horse_img, binary_mask(horse_img), mode)\n",
    "\n",
    "    f, axarr = plt.subplots(1,3)\n",
    "    axarr[0].imshow(fish_img, cmap='gray')\n",
    "    axarr[1].imshow(horse_img, cmap='gray')\n",
    "    axarr[2].imshow(blend_img,cmap='gray')\n",
    "    \n",
    "test_blend(\"blend\")\n",
    "test_blend(\"overlay\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 5: Creating Panoramas\n",
    "====\n",
    "\n",
    "We are now ready to make a panorama from the three images at the beginning. The function below receives a Python list of images, which you should stitch together to form one large image. You will need to call most of the functions defined above in order to successfully do this. \n",
    "\n",
    "To receive full credit, make sure you have stitched the three images together with very little seam between them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stitch_img(imgs):\n",
    "    '''Stitch a list of images together.\n",
    "    \n",
    "    Input: \n",
    "        imgs: a list of images.\n",
    "    Output:\n",
    "        stitched_img: a single stiched image.\n",
    "        \n",
    "    TODO: implement the stitch_img function. \n",
    "    '''\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the below code to test your implementation. This code just reads in the images, calls the stitch_img() function, and plots the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "center_img = cv2.imread(\"mountain_center.png\")\n",
    "left_img = cv2.imread(\"mountain_left.png\")\n",
    "right_img = cv2.imread(\"mountain_right.png\")\n",
    "\n",
    "final_img = stitch_img([center_img, left_img, right_img])\n",
    "\n",
    "plt.imshow(cv2.cvtColor(final_img.astype(\"uint8\"), cv2.COLOR_BGR2RGB));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make Your Own Panarama\n",
    "--- \n",
    "\n",
    "Use a digital camera, such as from your phone, and take three or more photos to create your own panaroma. Remember to be stand in place and only rotate the camera (Think about: why?). Include them in your submission, and we will show the best ones during lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list = []  ''' TODO: Load your own images here and create a panorama. '''\n",
    "\n",
    "final_img = stitch_img(img_list)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(final_img.astype(\"uint8\"), cv2.COLOR_BGR2RGB));"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
