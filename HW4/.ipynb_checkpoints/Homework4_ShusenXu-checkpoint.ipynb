{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homework 4\n",
    "==========\n",
    "\n",
    "There are two parts of this homework. In the first part, you need to implement the backward pass of the **fully-connected layer** and the **convolutional layer**. In the second part, we play around with **finetuning** and **adversarial attacks** on the neural networks!\n",
    "\n",
    "- **Task 1: Implement NN Layers (60 points)**\n",
    "    - Implement the `backward_pass` of fully connected layer (30 points).\n",
    "    - Implement the `backward_pass` of convolutional layer (30 points).\n",
    "- **Task 2: Fintuning and Adversarial Attacks (40 points)**\n",
    "    - Implement the `train` function to complete fintuinig (20 points, 5 points per correct label in testing).\n",
    "    - Adversarial attacks on 4 images of 4 classes (5 points each).\n",
    "\n",
    "- Your job is to implement the sections marked with TODO to complete the tasks.\n",
    "\n",
    "- Submission \n",
    "    - Please submit the notebook (ipynb and pdf) including the output of all cells.\n",
    "\n",
    "- Note: Please install PyTorch on your machine by running the following command in the terminal:\n",
    "    - `pip install -U torch torchvision`\n",
    "    - More guideline can be found on [PyTorch Official Website](https://pytorch.org/get-started/locally/)\n",
    "    - Task 2 is not computational intensive so you can run it on your local machine's CPU.\n",
    "    - If you want to use GPU, try [Google CoLab](https://colab.research.google.com/) and there are usually free GPUs available. \n",
    "    - There are some [tutorials](https://towardsdatascience.com/getting-started-with-google-colab-f2fff97f594c) available on how to use Colab's GPU and have your own storage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running notes\n",
    "-----\n",
    "\n",
    "### run task1 and task2 separately\n",
    "Experienced the death of process, I got this idea\n",
    "\n",
    "When running all together, the death of kernel may happen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1 - Implemenet NN Layers\n",
    "-----\n",
    "\n",
    "### 1.1 Fully Connected Layer\n",
    "Before we get started, let's recall what happens in the forward pass of a full-connected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "class Linear():\n",
    "    \"\"\"A fully-connected NN layer.\n",
    "    Parameters:\n",
    "    -----------\n",
    "    n_units: int\n",
    "        The number of neurons in the layer.\n",
    "    input_shape: tuple\n",
    "        The expected input shape of the layer. For dense layers a single digit specifying\n",
    "        the number of features of the input. Must be specified if it is the first layer in\n",
    "        the network.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_units, input_shape=None):\n",
    "        # For simplisity, we omit optimizer in our homework.\n",
    "        # Therefore, you do not need to worry about parameter update.\n",
    "        self.layer_input = None\n",
    "        self.input_shape = input_shape\n",
    "        self.n_units = n_units\n",
    "        self.trainable = True\n",
    "        self.W = None\n",
    "        self.b = None\n",
    "        self.initialize()\n",
    "\n",
    "    def initialize(self):\n",
    "        # Initialize the weights\n",
    "        limit = 1 / math.sqrt(self.input_shape[0])\n",
    "        self.W  = np.random.uniform(-limit, limit, (self.input_shape[1], self.n_units))\n",
    "        self.b = np.zeros((1, self.n_units))\n",
    "\n",
    "    def forward_pass(self, inp):\n",
    "        self.layer_input = inp\n",
    "        return np.dot(inp, self.W) + self.b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we provided some helper functions that might be useful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SE(out, target):\n",
    "    '''\n",
    "    return square error.\n",
    "    '''\n",
    "    return 0.5 * (target - out)**2\n",
    "\n",
    "def get_target(inp, W, b):\n",
    "    '''\n",
    "    W and b are assumed ideal weights and bias.\n",
    "    '''\n",
    "    return np.dot(inp, W) + b\n",
    "\n",
    "def grad_check(layer, inp, W, b):\n",
    "    '''\n",
    "    calculate gradient from numerical method, we compare the analytical gradient and numerical gradient.\n",
    "    \n",
    "    We say your calculated gradients are correct when the mean square error between \n",
    "    standard gradient and your gradient is below some threshold.\n",
    "    \n",
    "    return true when gradients of W, b and inp are calculated correctly.\n",
    "    '''\n",
    "    res = True\n",
    "    target = get_target(inp, W, b)\n",
    "    out = layer.forward_pass(inp)\n",
    "    y = SE(target, out)\n",
    "    loss = target - out\n",
    "    accum_grad = layer.backward_pass(loss)\n",
    "    \n",
    "    W_shape = layer.W.shape\n",
    "    b_shape = layer.b.shape\n",
    "    inp_shape = inp.shape\n",
    "    \n",
    "    limit = 1e-6\n",
    "    threshold = 1e-8 * inp_shape[0]**2\n",
    "    \n",
    "    W_diff = np.zeros(W_shape)\n",
    "    for i in range(W_shape[0]):\n",
    "        noise = np.random.rand(W_shape[1]) * limit\n",
    "        layer.W[i,:] += noise\n",
    "        out2 = layer.forward_pass(inp)\n",
    "        y2 = SE(target, out2)\n",
    "        W_diff[i,:] = np.sum(y - y2, axis=0) / noise\n",
    "        layer.W[i,:] -= noise\n",
    "        \n",
    "    res &= (np.sum((W_diff - layer.grad_W)**2) < threshold)\n",
    "    \n",
    "    noise = np.random.rand(*b_shape) * limit\n",
    "    layer.b += noise\n",
    "    out2 = layer.forward_pass(inp)\n",
    "    y2 = SE(target, out2)\n",
    "    b_diff = np.sum(y - y2, axis=0) / noise\n",
    "    layer.b -= noise   \n",
    "    \n",
    "    res &= (np.sum((b_diff - layer.grad_b)**2) < threshold)\n",
    "    \n",
    "    inp_diff = np.zeros(inp_shape)\n",
    "    for j in range(inp_shape[1]):\n",
    "        noise = np.random.rand(inp_shape[0]) * limit\n",
    "        inp[:,j] += noise\n",
    "        out2 = layer.forward_pass(inp)\n",
    "        y2 = SE(target, out2)\n",
    "        inp_diff[:,j] = np.sum(y - y2, axis=1) / noise\n",
    "        inp[:,j] -= noise\n",
    " \n",
    "    res &= (np.sum((inp_diff - accum_grad)**2) < threshold) \n",
    "    \n",
    "    return res\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement the Backward Pass\n",
    "Now you can start building your own backward function of the fully connected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_pass_fc(self, accum_grad):\n",
    "    '''\n",
    "    TODO: Implement the backward_pass_fc here.\n",
    "    \n",
    "    Parameter:\n",
    "    ----------\n",
    "        accum_grad: gradient propogated back from the next layer\n",
    "        \n",
    "    Return:\n",
    "    ----------\n",
    "        accum_grad_result: gradient propogated back from the this layer\n",
    "    '''\n",
    "    \n",
    "    self.grad_W = 0\n",
    "    self.grad_b = 0\n",
    "    accum_grad_result = np.zeros(self.layer_input.shape)\n",
    "    \n",
    "    # the gradient of weights\n",
    "    self.grad_W = self.layer_input.T.dot(accum_grad)\n",
    "    \n",
    "    # the gradient of bias\n",
    "    grad_out_b = np.ones([1,100])  \n",
    "    self.grad_b = grad_out_b.dot(accum_grad)\n",
    "      \n",
    "    # the gradient of input\n",
    "    accum_grad_result = accum_grad.dot(self.W.T) \n",
    "    \n",
    "    \n",
    "    return accum_grad_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test your implementation\n",
    "Use grad_check to test the correctness of your backward implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Testing Backward Pass: Pass!\n"
     ]
    }
   ],
   "source": [
    "Linear.backward_pass = backward_pass_fc\n",
    "\n",
    "inp = np.random.rand(100,3)\n",
    "layer = Linear(2, inp.shape)\n",
    "\n",
    "W = np.random.rand(3,2)\n",
    "b = np.random.rand(1,2)\n",
    "\n",
    "if grad_check(layer, inp, W, b):\n",
    "    print(\"[INFO] Testing Backward Pass: Pass!\")\n",
    "else:\n",
    "    print(\"[WARN] Testing Backward Pass: Fail!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Convolutional Layer\n",
    "Before we get started, let's recall what happens in the forward pass of a convolutional layer.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2D():\n",
    "    \"\"\"A 2D Convolution Layer.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    n_filters: int\n",
    "        The number of filters that will convolve over the input matrix. The number of channels\n",
    "        of the output shape.\n",
    "    filter_shape: tuple\n",
    "        A tuple (filter_height, filter_width).\n",
    "    input_shape: tuple\n",
    "        The shape of the expected input of the layer. (batch_size, channels, height, width)\n",
    "        Only needs to be specified for first layer in the network.\n",
    "    padding: string\n",
    "        Either 'same' or 'valid'. 'same' results in padding being added so that the output height and width\n",
    "        matches the input height and width. For 'valid' no padding is added.\n",
    "        By default, we use 'same' to test the implementation.\n",
    "    stride: int\n",
    "        The stride length of the filters during the convolution over the input.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_filters, filter_shape, input_shape, padding='same', stride=1):\n",
    "        self.n_filters = n_filters\n",
    "        self.filter_shape = filter_shape\n",
    "        self.padding = padding\n",
    "        self.stride = stride\n",
    "        self.input_shape = input_shape\n",
    "        self.trainable = True\n",
    "        self.W = None\n",
    "        self.w0 = None\n",
    "        self.initialize()\n",
    "\n",
    "    def initialize(self):\n",
    "        # Initialize the weights\n",
    "        filter_height, filter_width = self.filter_shape\n",
    "        batch, channels, height, width = self.input_shape\n",
    "        limit = 1 / math.sqrt(np.prod(self.filter_shape))\n",
    "        self.W  = np.random.uniform(-limit, limit, size=(self.n_filters, channels, filter_height, filter_width))\n",
    "        self.w0 = np.zeros((self.n_filters, 1))\n",
    "\n",
    "    def output_shape(self):\n",
    "        batch, channels, height, width = self.input_shape\n",
    "        pad_h, pad_w = determine_padding(self.filter_shape, output_shape=self.padding)\n",
    "        output_height = (height + np.sum(pad_h) - self.filter_shape[0]) / self.stride + 1\n",
    "        output_width = (width + np.sum(pad_w) - self.filter_shape[1]) / self.stride + 1\n",
    "        return self.n_filters, int(output_height), int(output_width)\n",
    "    \n",
    "    def forward_pass(self, X):\n",
    "        batch_size, channels, height, width = X.shape\n",
    "        self.layer_input = X\n",
    "        # Turn image shape into column shape\n",
    "        # (enables dot product between input and weights)\n",
    "        self.X_col = image_to_column(X, self.filter_shape, stride=self.stride, output_shape=self.padding)\n",
    "        #the shape of self.X_col   (27, 25)\n",
    "        # Turn weights into column shape\n",
    "        self.W_col = self.W.reshape((self.n_filters, -1))\n",
    "        #the shape of self.W.col    (5, 27)\n",
    "        # Calculate output\n",
    "        output = self.W_col.dot(self.X_col) + self.w0\n",
    "        \n",
    "        # the shape of output_forward1:   (5, 25)\n",
    "        # Reshape into (n_filters, out_height, out_width, batch_size)\n",
    "        output = output.reshape(self.output_shape() + (batch_size, ))\n",
    "\n",
    "        # the shape of output_forward2:   (5, 5, 5, 1)\n",
    "        # Redistribute axises so that batch size comes first)\n",
    "        return output.transpose(3,0,1,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we provided some helper functions that might be useful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method which turns the image shaped input to column shape.\n",
    "# Used during the forward pass.\n",
    "# Reference: CS231n Stanford\n",
    "def image_to_column(images, filter_shape, stride, output_shape='same'):\n",
    "    filter_height, filter_width = filter_shape\n",
    "\n",
    "    pad_h, pad_w = determine_padding(filter_shape, output_shape)\n",
    "\n",
    "\n",
    "    # Add padding to the image\n",
    "    images_padded = np.pad(images, ((0, 0), (0, 0), pad_h, pad_w), mode='constant')\n",
    "    \n",
    "    \n",
    "    # Calculate the indices where the dot products are to be applied between weights\n",
    "    # and the image\n",
    "    k, i, j = get_im2col_indices(images.shape, filter_shape, (pad_h, pad_w), stride)\n",
    "    \n",
    "    #print(\"K:  \", np.shape(k))\n",
    "    #print(\"i   \", np.shape(i))\n",
    "    #print(\"j   \", np.shape(j))\n",
    "    \n",
    "    # Get content from image at those indices\n",
    "    cols = images_padded[:, k, i, j]\n",
    "    channels = images.shape[1]\n",
    "    # Reshape content into column shape\n",
    "    cols = cols.transpose(1, 2, 0).reshape(filter_height * filter_width * channels, -1)\n",
    "    return cols\n",
    "\n",
    "# Reference: CS231n Stanford\n",
    "def get_im2col_indices(images_shape, filter_shape, padding, stride=1):\n",
    "    # First figure out what the size of the output should be\n",
    "    batch_size, channels, height, width = images_shape\n",
    "    filter_height, filter_width = filter_shape\n",
    "    pad_h, pad_w = padding\n",
    "    out_height = int((height + np.sum(pad_h) - filter_height) / stride + 1)\n",
    "    out_width = int((width + np.sum(pad_w) - filter_width) / stride + 1)\n",
    "\n",
    "    i0 = np.repeat(np.arange(filter_height), filter_width)\n",
    "    i0 = np.tile(i0, channels)\n",
    "    i1 = stride * np.repeat(np.arange(out_height), out_width)\n",
    "    j0 = np.tile(np.arange(filter_width), filter_height * channels)\n",
    "    j1 = stride * np.tile(np.arange(out_width), out_height)\n",
    "    i = i0.reshape(-1, 1) + i1.reshape(1, -1)\n",
    "    j = j0.reshape(-1, 1) + j1.reshape(1, -1)\n",
    "\n",
    "    k = np.repeat(np.arange(channels), filter_height * filter_width).reshape(-1, 1)\n",
    "\n",
    "    return (k, i, j)\n",
    "\n",
    "# Method which calculates the padding based on the specified output shape and the\n",
    "# shape of the filters\n",
    "def determine_padding(filter_shape, output_shape=\"same\"):\n",
    "    # No padding\n",
    "    if output_shape == \"valid\":\n",
    "        return (0, 0), (0, 0)\n",
    "    # Pad so that the output shape is the same as input shape (given that stride=1)\n",
    "    elif output_shape == \"same\":\n",
    "        filter_height, filter_width = filter_shape\n",
    "\n",
    "        # Derived from:\n",
    "        # output_height = (height + pad_h - filter_height) / stride + 1\n",
    "        # In this case output_height = height and stride = 1. This gives the\n",
    "        # expression for the padding below.\n",
    "        pad_h1 = int(math.floor((filter_height - 1)/2))\n",
    "        pad_h2 = int(math.ceil((filter_height - 1)/2))\n",
    "        pad_w1 = int(math.floor((filter_width - 1)/2))\n",
    "        pad_w2 = int(math.ceil((filter_width - 1)/2))\n",
    "\n",
    "        return (pad_h1, pad_h2), (pad_w1, pad_w2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement Backward Pass\n",
    "Now you can start building your own backward function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_pass_conv(layer, accum_grad):\n",
    "    '''\n",
    "    TODO: Implement the backward_pass_fc here.\n",
    "    \n",
    "    Parameter:\n",
    "    ----------\n",
    "        accum_grad: gradient propogated back from the next layer\n",
    "        \n",
    "    Return:\n",
    "    ----------\n",
    "        accum_grad_result: gradient propogated back from the this layer\n",
    "    '''\n",
    "    accum_grad_result = np.zeros(layer.layer_input.shape)\n",
    "     \n",
    "    back_pass_w = layer.W.transpose(1,0,2,3)\n",
    "    \n",
    "    #flip\n",
    "    back_pass_w = np.flip(back_pass_w, (2,3))\n",
    "    # the shape of back_pass_w: 3*5*3*3 \n",
    "   \n",
    "    \n",
    "    #initialize: \n",
    "    \n",
    "    # filter_shape: layer.filter_shape\n",
    "    \n",
    "    # the num of filters: 3\n",
    "    n_filters = back_pass_w.shape[0]\n",
    "    # padding: \"same\"\n",
    "    padding = \"same\"\n",
    "    # stride = 1\n",
    "    stride = layer.stride\n",
    "    \n",
    "    #modify the forward_pass, consider the accum_grad as the input\n",
    "    batch_size, channels, height, width = accum_grad.shape\n",
    "    \n",
    "    X_col_accum_grad = image_to_column(accum_grad, layer.filter_shape, stride=1, output_shape=\"same\")\n",
    "    \n",
    "    W_col_back_pass = back_pass_w.reshape((n_filters, -1))\n",
    "        \n",
    "    result = W_col_back_pass.dot(X_col_accum_grad)\n",
    "    # determine the output_shape \n",
    "    pad_h, pad_w = determine_padding(layer.filter_shape, output_shape= padding)\n",
    "    output_height = (height + np.sum(pad_h) - layer.filter_shape[0]) / stride + 1\n",
    "    output_width = (width + np.sum(pad_w) - layer.filter_shape[1]) / stride + 1\n",
    "    \n",
    "    # Reshape into (n_filters, out_height, out_width, batch_size)\n",
    "    result_shape = (n_filters, int(output_height), int(output_width))\n",
    "    result = result.reshape(result_shape + (batch_size, ))\n",
    "    \n",
    "    # Redistribute axises so that batch size comes first\n",
    "    accum_grad_result = result.transpose(3,0,1,2)\n",
    "    #print(\"the shape of accum_grad_result    \", np.shape(accum_grad_result))\n",
    "    \n",
    "    return accum_grad_result\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test your implementation:\n",
    "We use preloaded input, output, weight and bias tensor to test the implementation of your forward pas and backward pass. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_test():\n",
    "    Conv2D.backward_pass = backward_pass_conv\n",
    "    \n",
    "    # np.load return the k,v pair of the name and value of numpy matrix\n",
    "    data = np.load('test.npz')\n",
    "    \n",
    "    #print(\"the type of data  \",data)\n",
    "    \n",
    "    # read the input from npz file\n",
    "    input_tensor = data['input_tensor']\n",
    "   \n",
    "    \n",
    "    \n",
    "    # read the forward pass result from npz file\n",
    "    output_tensor = data['output_tensor']\n",
    "   \n",
    "    # read the target from npz file\n",
    "    target_tensor = data['target_tensor']\n",
    "   \n",
    "    \n",
    "    # read the backward pass result from npz file\n",
    "    accum_grad = data['accum_grad']\n",
    "   \n",
    "    \n",
    "    # read the preloaded weight and bias from npz file\n",
    "    w0 = data['w0']\n",
    "   \n",
    "    W = data['W']\n",
    "\n",
    "    # read the configuration from npz file\n",
    "    filter_size = data['filter_size']\n",
    "    filter_num = data['filter_num']\n",
    "    \n",
    "    # configure the \n",
    "    layer = Conv2D(n_filters=filter_num, filter_shape=(filter_size, filter_size), input_shape=input_tensor.shape)\n",
    "    layer.W, layer.w0 = W, w0\n",
    "    predict_tensor = layer.forward_pass(input_tensor)\n",
    "    \n",
    "    \n",
    "    # Test the forward pass implementation\n",
    "    if SE(predict_tensor, output_tensor).all() < 1e-1:\n",
    "        print(\"[INFO] Testing Forward: Pass!\")\n",
    "    else:\n",
    "        print(\"[WARN] Testing Forward: Fail!\")\n",
    "    \n",
    "    # use the tensors read from the npz file to compute the loss\n",
    "    loss = target_tensor - output_tensor\n",
    "    \n",
    "    predict_accum_grad = layer.backward_pass(loss)\n",
    "        \n",
    "    \n",
    "    # Test the backward pass implementation\n",
    "    if SE(predict_accum_grad, accum_grad).all() < 1e-1:\n",
    "        print(\"[INFO] Testing Backward: Pass!\")\n",
    "    else:\n",
    "        print(\"[WARN] Testing Backward: Fail!\")\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Testing Forward: Pass!\n",
      "[INFO] Testing Backward: Pass!\n"
     ]
    }
   ],
   "source": [
    "conv_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2 - Finetuning and Adversarial Attacks\n",
    "-----\n",
    "\n",
    "### Setup\n",
    "We are using [MobileNetV2](https://arxiv.org/abs/1801.04381) archiecture for this task, which is light-weighted so don't worry if you don't have access to GPUs.    \n",
    "Also, we encourage you to try the code on [Google CoLab](https://colab.research.google.com/), usually there are free GPUs available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from model import MobileNetV2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Fintuning MobileNetV2 on  NanoImageNet:\n",
    "We prepare a very tiny dataset called NanoImageNet and split it into training and testing set. \n",
    "- training set `dataset/train`:\n",
    "    - 4 classes, each of 50 images, for finetunin.\n",
    "- testing set `dataset/test`:\n",
    "    - 4 classes, each of 1 image, for adversarial attack.\n",
    "\n",
    "We provide the essential code to load the model and images below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] PyTorch is now running on cpu mode.\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\" \".join([\"[INFO] PyTorch is now running on\", device, \"mode.\"]))\n",
    "\n",
    "testdir = 'dataset/test/'\n",
    "traindir = 'dataset/train/'\n",
    "\n",
    "tiny_imagenet_labels = ['husky', 'jeans', 'minvan', 'wallet']\n",
    "\n",
    "imagenet_labels = json.load(open(\"dataset/imagenet_labels.json\"))\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "input_size = 224\n",
    "\n",
    "# test dataset and loader\n",
    "test_dataset = torchvision.datasets.ImageFolder(\n",
    "    testdir,\n",
    "    transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.CenterCrop(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# train dataset and loader\n",
    "train_dataset = torchvision.datasets.ImageFolder(\n",
    "    traindir,\n",
    "    transforms.Compose([\n",
    "        transforms.RandomResizedCrop(input_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the weights form ImageNet pretrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = MobileNetV2(n_class=4)\n",
    "net = net.to(device)\n",
    "\n",
    "def load_model():\n",
    "    if device == 'cuda':\n",
    "        loaded_state_dict = torch.load('checkpoint/mobilenet_v2.pth.tar')\n",
    "    else:\n",
    "        loaded_state_dict = torch.load('checkpoint/mobilenet_v2.pth.tar', map_location='cpu')\n",
    "        \n",
    "    init_state_dict = net.state_dict()\n",
    "\n",
    "    from collections import OrderedDict\n",
    "    my_state_dict = OrderedDict()\n",
    "\n",
    "    print('===> Loading from pretrained ImageNet model')\n",
    "\n",
    "    for k, v in loaded_state_dict.items():\n",
    "        if('classifier.1' in k):\n",
    "            pass\n",
    "        else:\n",
    "            my_state_dict[k] = v\n",
    "\n",
    "    for k, v in init_state_dict.items():\n",
    "        if('classifier.1' in k):\n",
    "            my_state_dict[k] = init_state_dict[k]\n",
    "\n",
    "    net.load_state_dict(my_state_dict)\n",
    "\n",
    "params_net = []\n",
    "for child in net.children():\n",
    "    for name, param in net.named_parameters():\n",
    "        if('classifier.1' in name):\n",
    "            params_net.append(param)\n",
    "            # only finetune the last layer\n",
    "            param.requires_grad = True\n",
    "        else:\n",
    "            param.requires_grad = False\n",
    "\n",
    "params_list = [{'params': filter(lambda p: p.requires_grad, params_net), 'lr': 1e-2}]\n",
    "\n",
    "#Let’s use a Classification Cross-Entropy loss and Adam with momentum\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params_list, lr=1e-2, betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetuning on NanoImageNet:\n",
    "Here you need to finetune the network on the new NanoImageNet dataset we provide. Get familiar with pytorch and complete the `train` function below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    '''\n",
    "    TODO: complete the trian func here\n",
    "    '''\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 24 == 23:    # print every 24 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 24))\n",
    "            running_loss = 0.0\n",
    "        \n",
    "\n",
    "def adjust_learning_rate(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = param_group['lr'] * 0.1\n",
    "\n",
    "def test(attack=False):\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    net.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            if attack:\n",
    "                outputs = net(adv_attack(inputs, batch_idx))\n",
    "            else:\n",
    "                outputs = net(inputs)\n",
    "            \n",
    "            _, predict = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predict.eq(targets).sum().item()\n",
    "            \n",
    "            for i in range(predict.size()[0]):\n",
    "                if attack:\n",
    "                    predict_class = imagenet_labels[predict[i]]\n",
    "                else:\n",
    "                    predict_class = tiny_imagenet_labels[predict[i]]\n",
    "                    \n",
    "                target_class = tiny_imagenet_labels[targets[i]]\n",
    "                \n",
    "                print('Prediction: ' + predict_class + ', Groundtruth: ' + target_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Loading from pretrained ImageNet model\n",
      "iteration:   1\n",
      "[2,    24] loss: 4.098\n",
      "iteration:   2\n",
      "[3,    24] loss: 1.625\n",
      "iteration:   3\n",
      "[4,    24] loss: 0.662\n",
      "iteration:   4\n",
      "[5,    24] loss: 0.723\n",
      "Finish traning\n"
     ]
    }
   ],
   "source": [
    "load_model()\n",
    "for epoch in range(1, 5):\n",
    "    print(\"iteration:  \", epoch)\n",
    "    train(epoch)\n",
    "    if epoch % 1 == 0:\n",
    "        adjust_learning_rate(optimizer)\n",
    "print(\"Finish traning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the finetuned model\n",
    "To ease the process of grading, we do a naive testing on the small test set of 4 images (in real world, train/test split is usually 8:2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: husky, Groundtruth: husky\n",
      "Prediction: jeans, Groundtruth: jeans\n",
      "Prediction: minvan, Groundtruth: minvan\n",
      "Prediction: wallet, Groundtruth: wallet\n"
     ]
    }
   ],
   "source": [
    "test(attack=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Adversarial Attack\n",
    "Adversarial examples are inputs to machine learning models that an attacker has intentionally designed to cause the model to make a mistake; they’re like optical illusions for machines, but usually not very perceptible to human beings. \n",
    "\n",
    "One example provided in [OpenAI's blog](https://openai.com/blog/adversarial-example-research/):   \n",
    "\n",
    "![](pics/demo.png)\n",
    "\n",
    "In this task, you need to figure out ways to launch one naive adversarial attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ImageNet pretrained model back for adversarial attack\n",
    "net = MobileNetV2(n_class=1000)\n",
    "net = net.to(device)\n",
    "\n",
    "if device == 'cuda':\n",
    "    net.load_state_dict(torch.load('checkpoint/mobilenet_v2.pth.tar'))\n",
    "else:\n",
    "    net.load_state_dict(torch.load('checkpoint/mobilenet_v2.pth.tar', map_location='cpu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement the Attack:\n",
    "Here you need to add your modification to the input tensor to achieve the attack. We will count one attack successful if:\n",
    "1. The visualization of the noise is merely perceptible (or random pattern) to human eyes.    \n",
    "AND     \n",
    "2. The MSE of the original input tensor and the modified tensor is below the threshold.    \n",
    "AND      \n",
    "3. The network classifies the image to class other than groundtruth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adv_attack(inputs, batch_idx):\n",
    "    noise = torch.zeros_like(inputs).to(device)\n",
    "    '''\n",
    "    TODO: Implement modification to noise here, achieve the attack\n",
    "    \n",
    "    '''\n",
    "    '''\n",
    "    # Collect the element-wise sign of the data gradient\n",
    "    sign_data_grad = data_grad.sign()\n",
    "    # Create the perturbed image by adjusting each pixel of the input image\n",
    "    perturbed_image = image + epsilon*sign_data_grad\n",
    "    # Adding clipping to maintain [0,1] range\n",
    "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
    "    # Return the perturbed image\n",
    "    '''\n",
    "    \n",
    "    final = inputs + noise\n",
    "    \n",
    "    if torch.mean(inputs-final).abs() <= 1e-3:\n",
    "        print(\"[INFO] Attack MSE <= threshold\")\n",
    "    else:\n",
    "        print(\"[WARN] Attack MSE > threshold\")\n",
    "        \n",
    "    inputs_renorm = (inputs - inputs.min()) / (inputs.max()-inputs.min())\n",
    "    noise_renorm = (noise - noise.min()) / (noise.max()-noise.min())\n",
    "    final_renorm = (final - final.min()) / (final.max()-final.min())\n",
    "    \n",
    "    input_numpy = inputs_renorm [0].permute(1, 2, 0).cpu().detach().numpy()\n",
    "    noise_numpy = noise_renorm [0].permute(1, 2, 0).cpu().detach().numpy()\n",
    "    final_numpy = final_renorm [0].permute(1, 2, 0).cpu().detach().numpy()\n",
    "    \n",
    "    fig = plt.subplot(4,3,batch_idx*3+1)\n",
    "    fig.imshow(input_numpy)\n",
    "    fig.text(15, 20, 'original', bbox={'facecolor': 'white', 'pad': 10})\n",
    "    fig = plt.subplot(4,3,batch_idx*3+2)\n",
    "    fig.imshow(noise_numpy)\n",
    "    fig.text(15, 20, 'noise', bbox={'facecolor': 'white', 'pad': 10})\n",
    "    fig = plt.subplot(4,3,batch_idx*3+3)\n",
    "    fig.imshow(final_numpy)\n",
    "    fig.text(15, 20, 'final', bbox={'facecolor': 'white', 'pad': 10})\n",
    "    \n",
    "    return final\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 2880x2880 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.figure(figsize=(20,20), dpi=144)\n",
    "#test(attack=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
